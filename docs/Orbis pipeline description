Orbis is a extendable evaluation pipeline written in Python 3.6. ???? It is controlled using YAML configuration files and accesses plugins to perform specific tasks. 

Starting Orbis, a folder containing the YAML files is accessed and all the YAML files therein are queued to be processed in the pipeline as evaluation-runs. Every YAML file creates its own specific configuration pipeline by specifying the data source, the data aggregator to be used, the types of evaluation and scorers to run as well as how the results should be saved and displayed.

The aggregator is the first component of the pipeline. It is designed to collect all the data nedded for an evaluation run and storing it in a json compatible file object (a Python dict). This file object contains the corpus data, the gold standard results, and the computed results as well as placeholders for the evaluation results and is initialized by the aggregator to be passed down along the pipeline.

To fetch the computed results the aggregator can either get the data from a local storage or by accessing a webservice. Fetching the data from a webservice is done by sending the corpusn content to the webservice api and integrating the result into the file object. When utelizing the local storage, previously saved results from the webservices are used instead of querying the webservices again. Creating and refreshing these local caches can be controlled from within the YAML files. Access to different webservices can be implemented into Orbis by creating a new plugin and specifying its use in a YAML file.

Additionally to storing the data the aggregator also preforms some normalization steps on the gold standard as well as the computed results like mapping redirecting URIs to their destination, applying lenses in order to ::::::::::::::::::::::::::::::::::::::::::: , and applying filters to remove unwanted content as well as querying DBpedia's SPARQL endpoint in order to 

After all the data is collected and stored in the file object, this object is passed further to the evaluation component.

The evaluation component evaluates the results by comparing the computed data set with the gold standard. This comparison is done by a scorer plugin, that specifies what criteria must be met in order to count as a hit (e.g.: must surface form be an exact match or does overlapping also count). The scorer returns a confusion matrix with true positive, false positive, and false nergative values. 
These values are used to calculate metrics by a metrics plugin, e.g.: for named entity linking precision, recall, and f1 score. Additionally the evaluation component can also filter by entity type, defined in the YAML file, in order to perform evaluations on specific types of entities, e.g.: how well are only persons or only locations recognized.  Since the metrics are not only saved per corpus but also per corpus item, macro as well as micro precision, recall and f1 score are supported (GERBIL LINK).

The file object, now containing the corpus, the gold standard, the computed data as well as the evaluation results is passed to the last step of the pipeline to store them. 
The saving component can save the results in multiple formats and forms by utilizing a variety of plugins. The data can be saved as JSON file containing either the complete pipeline data object or just the results. The same can be done in the CSV format.

Additionally Orbis was originally concieved to visualize not only the end result of a evaluation run but also the single results composing the end result. To store, display, and also compare the end results Orbis can access a Graphite/Grafana installation to display the results as a graph over a longer period of time. Visualizing the single results is done using a HTML frontend that displays for every item in the corpus the gold results on the one side as well as the computed results on the other side. The seperate entities as collored in different colours and match colours if the both link to the same entity. If entities don't match, they are crossed out. Additionally the metrics to every single item of the corpus is displayed. This functionality was specifically designed for a drill-down analysis of not only the computed entities but also the gold standard entities.

